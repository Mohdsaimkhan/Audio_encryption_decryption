////////////////////////////////////////////////////////////////////////////
//
// Copyright 1993-2015 NVIDIA Corporation.  All rights reserved.
//
// Please refer to the NVIDIA end user license agreement (EULA) associated
// with this source code for terms and conditions that govern your use of
// this software. Any use, reproduction, disclosure, or distribution of
// this software and related documentation outside the terms of the EULA
// is strictly prohibited.
//
////////////////////////////////////////////////////////////////////////////

/* Template project which demonstrates the basics on how to setup a project
* example application.
* Host code.
*/

// includes, system
#include <stdlib.h>
#include <stdio.h>
#include <string.h>
#include <math.h>

// includes CUDA
#include <cuda_runtime.h>

// includes, project
#include <helper_cuda.h>
#include <helper_functions.h> // helper functions for SDK examples
#include "common.h"

////////////////////////////////////////////////////////////////////////////////
// declaration, forward
void runTest(int argc, char **argv);

////////////////////////////////////////////////////////////////////////////////
//! Simple test kernel for device functionality
//! @param g_idata  input data in global memory
//! @param g_odata  output data in global memory
////////////////////////////////////////////////////////////////////////////////
/*
 * warp reduction
 */
 __inline__ __device__
 DTYPE warpReduceSum(DTYPE val) {
   for (int offset = warpSize/2; offset > 0; offset /= 2)
	  val += __shfl_down_sync(0xffffffff, val, offset);
   return val;
 }

 /*
  * block reduction
  */
 __inline__ __device__
 DTYPE blockReduceSum(DTYPE val) {

   static __shared__ DTYPE sdata[32];
   int lane = threadIdx.x % warpSize;
   int wid = threadIdx.x / warpSize;

   __syncthreads();

   val = warpReduceSum(val);

   if (lane==0)
      sdata[wid]=val;
   __syncthreads();

   val = (threadIdx.x < blockDim.x / warpSize) ? sdata[lane] : 0;

   if (wid==0)
    val = warpReduceSum(val);

   return val;
 }
 
 /*
  * array reduction
  *
  *
  * int threads = 512;
  * int blocks = min((N + threads - 1) / threads, 1024);
  * deviceReduceKernel<<<blocks, threads>>>(in, out, N);
  * deviceReduceKernel<<<1, 1024>>>(out, out, blocks);
  */
 __global__ void deviceReduceKernel(DTYPE *in, DTYPE* out, int N) {
   DTYPE sum = 0.0;

   for (int i = blockIdx.x * blockDim.x + threadIdx.x; i < N; i += blockDim.x * gridDim.x) {
	    sum += in[i];
   }
   sum = blockReduceSum(sum);
   if (threadIdx.x==0)
	  out[blockIdx.x]=sum;
 }

 __global__ void warpReduce_demo() {
     int laneId = threadIdx.x & 0x1f;
     // Seed starting value as inverse lane ID
     int value = 31 - laneId;

	 //int i=16;
	 for (int i=warpSize/2; i>0; i/=2)
         value += __shfl_down_sync(0xffffffff, value, i);

     // "value" now contains the sum across all threads
     printf("Thread %d final value = %d\n", threadIdx.x, value);
 }


 __global__ void blockReduce_demo() {
   DTYPE val = 0.0;
   val = blockReduceSum(val);
   if (threadIdx.x == 0)
    printf("Thread %d final value = %f\n", threadIdx.x, val);
 }

int main(int argc, char **argv)
{
  //warpReduce_demo<<<1,32>>>();
  blockReduce_demo<<< 1, 1024 >>>();
  cudaDeviceSynchronize();
  return 0;
}

////////////////////////////////////////////////////////////////////////////////
//! Run a simple test for CUDA
////////////////////////////////////////////////////////////////////////////////
/*
void
runTest(int argc, char **argv)
{

    printf("%s Starting...\n\n", argv[0]);

    // use command-line specified CUDA device, otherwise use device with highest Gflops/s
    int devID = findCudaDevice(argc, (const char **)argv);

    StopWatchInterface *timer = 0;
    sdkCreateTimer(&timer);


    unsigned int threads_per_block = atoi(argv[2])  ;
    unsigned int nbsteps = atoi(argv[1]);
    nbsteps = nextPow2(nbsteps);
    unsigned long long mem_size = sizeof(DTYPE) * nbsteps;


    size_t memfree, memtotal;
    checkCudaErrors(cudaMemGetInfo(&memfree, &memtotal));

    // for info only
    unsigned int puis=0;
    unsigned int dec = nbsteps;
    while(dec > 1){
      dec /=10;
      puis++;
    }
    printf("nbsteps : %u = 10^%u - Memory size : %llu\n", nbsteps, puis, mem_size);
    printf("Memory total : %lu - Memory free : %lu\n", memtotal, memfree);


    // la moiti√© suffit selon l'option prise
    DTYPE *d_vector;
    checkCudaErrors(cudaMalloc((void **) &d_vector, mem_size));

    sdkStartTimer(&timer);
    // setup execution parameters
    int nblocks = (nbsteps+threads_per_block-1)/threads_per_block;
    dim3  grid(nblocks, 1, 1);
    dim3  threads(threads_per_block, 1, 1);

    //computeNstore<<< grid, threads, 0 >>> (d_vector, nbsteps, 1.0/nbsteps);
    printf("computeNstore terminated \n");
    cudaThreadSynchronize();
    // REDUCTION KERNEL CALLS
    sdkStopTimer(&timer);

    // copy result from device to host
    DTYPE h_outpi;
    checkCudaErrors(cudaMemcpy(&h_outpi, d_vector, sizeof(DTYPE),
                               cudaMemcpyDeviceToHost));


    printf("Processing time: %f (ms)\n", sdkGetTimerValue(&timer));
    DTYPE piGpu = 4.0 * (1.0/(double)nbsteps) * (h_outpi);
    DTYPE piGold = computeGold(nbsteps);
    printf("Pi     GPU : %.10lf \n", piGpu) ;
    printf("Pi ref CPU : %.10lf \n", piGold) ;

    sdkDeleteTimer(&timer);

    // compute reference solution
    if ( abs(piGpu - piGold) < 1e-9)
      printf("TEST PASSED.... (err %lf)x10^-9\n", 1e9*abs(piGpu - piGold));
    else
      printf("TEST FAILED !!!... (err %lf)x10^-9\n", 1e9*abs(piGpu - piGold));

    // cleanup memory
    checkCudaErrors(cudaFree(d_vector));

    exit(EXIT_SUCCESS);
	}
*/
